# -*- coding: utf-8 -*-
"""Final: HW4 ML course

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N5CS-MAMJKD98Uo4XpKQ8NB_mKpk4hsq

libraries:
"""

from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten

from keras.optimizers import adam
from keras.callbacks import Callback

from keras.utils import np_utils
from keras.datasets import cifar10
import numpy as np

import matplotlib.pyplot as plt

from keras import backend as K

import tensorflow as tf
import os
import random

from __future__ import print_function
from keras.models import load_model
import os


"""Dataset :"""

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
mean = np.mean(x_train,axis=(0,1,2,3))
std = np.std(x_train,axis=(0,1,2,3))
x_train = (x_train-mean)/(std+1e-7)
x_test = (x_test-mean)/(std+1e-7)
nClasses = 10
y_train = np_utils.to_categorical(y_train,nClasses)
y_test = np_utils.to_categorical(y_test,nClasses)


# for checking

print(x_train.shape)
print(y_train.shape)

"""Models:"""

input_shape = (32,32,3)

def DesginModel():
    model = Sequential()

    model.add(Conv2D(filters=32, kernel_size=(3, 3),activation='relu',input_shape=(32, 32, 3)))
    model.add(MaxPooling2D())
  
    model.add(Conv2D(filters=64,kernel_size=(3, 3),activation='relu'))
    model.add(MaxPooling2D())
    
    model.add(Flatten())
    model.add(Dense(10, activation='softmax'))
   
    return model

K.clear_session()
model = DesginModel()
model.summary()

#For printing
class CustomCallback(Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (epoch % 2 == 0):
          print ("Just finished epoch", epoch)
          print ('Accuracy of train', 
                 logs.get('acc'))
          print ('Accuracy of Val', 
                 logs.get('val_acc'))
          return

#Ooptimizer
AdamOpt = adam(lr=0.001)

#Compile the model
model.compile(optimizer=AdamOpt, loss='categorical_crossentropy', metrics=['accuracy'])

#training 
batch_size = 256
epochs = 30
CC = CustomCallback()
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_test, y_test), callbacks = [CC])

# Saveing this model
model.save('firstModel.h5')

"""**confusion matrix**"""

from sklearn.metrics import classification_report, confusion_matrix



y_pred = model.predict_classes(x_test)
yTest_original = np.argmax(y_test, axis = 1)

print("confusion matrix")
print(confusion_matrix(y_true=yTest_original, y_pred=y_pred ))

print("\n \n Recall and precision for each class")
print(classification_report(yTest_original, y_pred ))

"""**Prediction**"""

import random
import cv2 

try:
    from google.colab.patches import cv2_imshow
except Exception:
    def cv2_imshow(mat):
        return cv2.imshow('img', mat)

def url_to_image(url):
    from skimage import io
    return cv2.cvtColor(io.imread(url), cv2.COLOR_BGR2RGB)

  # deer : https://6.top4top.net/p_1415l3ll71.jpg
  # Cat :  https://2.top4top.net/p_1415dk5fc1.jpg
  # https://1.top4top.net/p_1415zq5vc2.jpg

url = 'https://1.top4top.net/p_1415zq5vc2.jpg'

img = url_to_image(url)
img = resized = cv2.resize(img, (32,32)) 

cifar10_labels = np.array([
    'airplane',
    'automobile',
    'bird',
    'cat',
    'deer',
    'dog',
    'frog',
    'horse',
    'ship',
    'truck'])


loaded_model = tf.keras.models.load_model('firstModel.h5')

    
def convertCIFER10Data(image):
    img = image.astype('float32')
    img /= 255
    c = np.zeros(32*32*3).reshape((1,32,32,3))
    c[0] = img
    return c

plt.figure(figsize=(16,16))
data = convertCIFER10Data(img)
plt.imshow(img)
ret = model.predict(data, batch_size=1) 
bestnum = 0.0
bestclass = 0
for n in [0,1,2,3,4,5,6,7,8,9]:
    if bestnum < ret[0][n]:
        bestnum = ret[0][n]
        bestclass = n


plt.title(cifar10_labels[bestclass])
                                                  
plt.show()

"""**Plots**"""

history_dict = history.history
loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']


# Loss Curves
plt.figure(figsize=[8,6])
plt.plot(history.history['loss'],'pink',linewidth=3.0)
plt.plot(history.history['val_loss'],'gray',ls = '--', linewidth=3.0)
plt.legend(['Training loss', 'Validation Loss'],fontsize=10)
plt.title('Training and validation loss',fontsize=15)
plt.xlabel('Epochs ',fontsize=15)
plt.ylabel('Loss',fontsize=15)

# Accuracy Curves
plt.figure(figsize=[8,6])
plt.plot(history.history['acc'],'pink',linewidth=3.0)
plt.plot(history.history['val_acc'],'gray',ls = '--',linewidth=3.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=10, 
           loc = 'lower right')
plt.xlabel('Epochs ',fontsize=15)
plt.ylabel('Accuracy',fontsize=15)
plt.title('Accuracy Curves',fontsize=15)